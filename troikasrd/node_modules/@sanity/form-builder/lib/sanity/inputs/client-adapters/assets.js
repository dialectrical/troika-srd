"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.materializeReference = materializeReference;
exports.uploadFileAsset = exports.uploadImageAsset = void 0;

var _operators = require("rxjs/operators");

var _rxjs = require("rxjs");

var _withMaxConcurrency = require("../../utils/withMaxConcurrency");

var _legacyParts = require("../../../legacyParts");

var _versionedClient = require("../../versionedClient");

var MAX_CONCURRENT_UPLOADS = 4;

function uploadSanityAsset(assetType, file) {
  var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
  var extract = options.metadata;
  var preserveFilename = options.storeOriginalFilename;
  var label = options.label,
      title = options.title,
      description = options.description,
      creditLine = options.creditLine,
      source = options.source;
  return hashFile(file).pipe((0, _operators.catchError)(() => // ignore if hashing fails for some reason
  (0, _rxjs.of)(null)), (0, _operators.mergeMap)(hash => // note: the sanity api will still dedupe unique files, but this saves us from uploading the asset file entirely
  hash ? fetchExisting("sanity.".concat(assetType, "Asset"), hash) : (0, _rxjs.of)(null)), (0, _operators.mergeMap)(existing => {
    if (existing) {
      return (0, _rxjs.of)({
        // complete with the existing asset document
        type: 'complete',
        id: existing._id,
        asset: existing
      });
    }

    return _versionedClient.versionedClient.observable.assets.upload(assetType, file, {
      tag: 'asset.upload',
      extract,
      preserveFilename,
      label,
      title,
      description,
      creditLine,
      source
    }).pipe((0, _operators.map)(event => event.type === 'response' ? {
      // rewrite to a 'complete' event
      type: 'complete',
      id: event.body.document._id,
      asset: event.body.document
    } : event));
  }));
}

var uploadAsset = (0, _withMaxConcurrency.withMaxConcurrency)(uploadSanityAsset, MAX_CONCURRENT_UPLOADS);

var uploadImageAsset = (file, options) => uploadAsset('image', file, options);

exports.uploadImageAsset = uploadImageAsset;

var uploadFileAsset = (file, options) => uploadAsset('file', file, options);

exports.uploadFileAsset = uploadFileAsset;

function materializeReference(id) {
  return (0, _legacyParts.observePaths)(id, ['originalFilename', 'url', 'metadata', 'label', 'title', 'description', 'creditLine', 'source']);
}

function fetchExisting(type, hash) {
  return _versionedClient.versionedClient.observable.fetch('*[_type == $documentType && sha1hash == $hash][0]', {
    documentType: type,
    hash
  }, {
    tag: 'asset.find-duplicate'
  });
}

function readFile(file) {
  return new _rxjs.Observable(subscriber => {
    var reader = new FileReader();

    reader.onload = () => {
      subscriber.next(reader.result);
      subscriber.complete();
    };

    reader.onerror = err => {
      subscriber.error(err);
    };

    reader.readAsArrayBuffer(file);
    return () => {
      reader.abort();
    };
  });
}

function hashFile(file) {
  if (!window.crypto || !window.crypto.subtle || !window.FileReader) {
    return (0, _rxjs.of)(null);
  }

  return readFile(file).pipe((0, _operators.mergeMap)(arrayBuffer => crypto.subtle.digest('SHA-1', arrayBuffer)), (0, _operators.map)(hexFromBuffer));
}

function hexFromBuffer(buffer) {
  return Array.prototype.map.call(new Uint8Array(buffer), x => "00".concat(x.toString(16)).slice(-2)).join('');
}