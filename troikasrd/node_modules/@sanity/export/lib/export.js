"use strict";

function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }

function _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err); } _next(undefined); }); }; }

var os = require('os');

var path = require('path');

var zlib = require('zlib');

var fse = require('fs-extra');

var miss = require('mississippi');

var split = require('split2');

var archiver = require('archiver');

var debug = require('./debug');

var AssetHandler = require('./AssetHandler');

var stringifyStream = require('./stringifyStream');

var validateOptions = require('./validateOptions');

var rejectOnApiError = require('./rejectOnApiError');

var getDocumentsStream = require('./getDocumentsStream');

var filterSystemDocuments = require('./filterSystemDocuments');

var filterDocumentTypes = require('./filterDocumentTypes');

var filterDrafts = require('./filterDrafts');

var logFirstChunk = require('./logFirstChunk');

var tryParseJson = require('./tryParseJson');

var noop = () => null;

function exportDataset(opts) {
  var options = validateOptions(opts);
  var onProgress = options.onProgress || noop;
  var archive = archiver('tar', {
    gzip: true,
    gzipOptions: {
      level: options.compress ? zlib.Z_DEFAULT_COMPRESSION : zlib.Z_NO_COMPRESSION
    }
  });
  var slugDate = new Date().toISOString().replace(/[^a-z0-9]/gi, '-').toLowerCase();
  var prefix = "".concat(opts.dataset, "-export-").concat(slugDate);
  var tmpDir = path.join(os.tmpdir(), prefix);

  var cleanup = () => fse.remove(tmpDir).catch(err => {
    debug("Error while cleaning up temporary files: ".concat(err.message));
  });

  var assetHandler = new AssetHandler({
    client: options.client,
    tmpDir,
    prefix,
    concurrency: options.assetConcurrency
  });
  debug('Outputting assets (temporarily) to %s', tmpDir);
  debug('Outputting to %s', options.outputPath === '-' ? 'stdout' : options.outputPath);
  var outputStream = options.outputPath === '-' ? process.stdout : fse.createWriteStream(options.outputPath);
  var assetStreamHandler = assetHandler.noop;

  if (!options.raw) {
    assetStreamHandler = options.assets ? assetHandler.rewriteAssets : assetHandler.stripAssets;
  }

  return new Promise( /*#__PURE__*/function () {
    var _ref = _asyncToGenerator(function* (resolve, reject) {
      miss.finished(archive, /*#__PURE__*/function () {
        var _ref2 = _asyncToGenerator(function* (archiveErr) {
          if (archiveErr) {
            debug('Archiving errored! %s', archiveErr.stack);
            yield cleanup();
            reject(archiveErr);
            return;
          }

          debug('Archive finished!');
        });

        return function (_x3) {
          return _ref2.apply(this, arguments);
        };
      }());
      debug('Getting dataset export stream');
      onProgress({
        step: 'Exporting documents...'
      });
      var documentCount = 0;
      var lastReported = Date.now();

      var reportDocumentCount = (chunk, enc, cb) => {
        ++documentCount;
        var now = Date.now();

        if (now - lastReported > 50) {
          onProgress({
            step: 'Exporting documents...',
            current: documentCount,
            total: '?',
            update: true
          });
          lastReported = now;
        }

        cb(null, chunk);
      };

      var inputStream = yield getDocumentsStream(options.client, options.dataset);
      debug('Got HTTP %d', inputStream.statusCode);
      debug('Response headers: %o', inputStream.headers);
      var jsonStream = miss.pipeline(inputStream, logFirstChunk(), split(tryParseJson), rejectOnApiError(), filterSystemDocuments(), assetStreamHandler, filterDocumentTypes(options.types), options.drafts ? miss.through.obj() : filterDrafts(), stringifyStream(), miss.through(reportDocumentCount));
      miss.finished(jsonStream, /*#__PURE__*/function () {
        var _ref3 = _asyncToGenerator(function* (err) {
          if (err) {
            return;
          }

          onProgress({
            step: 'Exporting documents...',
            current: documentCount,
            total: documentCount,
            update: true
          });

          if (!options.raw && options.assets) {
            onProgress({
              step: 'Downloading assets...'
            });
          }

          var prevCompleted = 0;
          var progressInterval = setInterval(() => {
            var completed = assetHandler.queueSize - assetHandler.queue.size - assetHandler.queue.pending;

            if (prevCompleted === completed) {
              return;
            }

            prevCompleted = completed;
            onProgress({
              step: 'Downloading assets...',
              current: completed,
              total: assetHandler.queueSize,
              update: true
            });
          }, 500);
          debug('Waiting for asset handler to complete downloads');

          try {
            var assetMap = yield assetHandler.finish(); // Make sure we mark the progress as done (eg 100/100 instead of 99/100)

            onProgress({
              step: 'Downloading assets...',
              current: assetHandler.queueSize,
              total: assetHandler.queueSize,
              update: true
            });
            archive.append(JSON.stringify(assetMap), {
              name: 'assets.json',
              prefix
            });
            clearInterval(progressInterval);
          } catch (assetErr) {
            clearInterval(progressInterval);
            yield cleanup();
            reject(assetErr);
            return;
          } // Add all downloaded assets to archive


          archive.directory(path.join(tmpDir, 'files'), "".concat(prefix, "/files"), {
            store: true
          });
          archive.directory(path.join(tmpDir, 'images'), "".concat(prefix, "/images"), {
            store: true
          });
          debug('Finalizing archive, flushing streams');
          onProgress({
            step: 'Adding assets to archive...'
          });
          archive.finalize();
        });

        return function (_x4) {
          return _ref3.apply(this, arguments);
        };
      }());
      archive.on('warning', err => {
        debug('Archive warning: %s', err.message);
      });
      archive.append(jsonStream, {
        name: 'data.ndjson',
        prefix
      });
      miss.pipe(archive, outputStream, onComplete);

      function onComplete(_x5) {
        return _onComplete.apply(this, arguments);
      }

      function _onComplete() {
        _onComplete = _asyncToGenerator(function* (err) {
          onProgress({
            step: 'Clearing temporary files...'
          });
          yield cleanup();

          if (!err) {
            resolve();
            return;
          }

          debug('Error during streaming: %s', err.stack);
          assetHandler.clear();
          reject(err);
        });
        return _onComplete.apply(this, arguments);
      }
    });

    return function (_x, _x2) {
      return _ref.apply(this, arguments);
    };
  }());
}

module.exports = exportDataset;